{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Classification-based-glottal-closure-instant-detection\" data-toc-modified-id=\"Classification-based-glottal-closure-instant-detection-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classification-based glottal closure instant detection</a></div><div class=\"lev2 toc-item\"><a href=\"#Training-the-classifier\" data-toc-modified-id=\"Training-the-classifier-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Training the classifier</a></div><div class=\"lev2 toc-item\"><a href=\"#Evaluating-the-classifier\" data-toc-modified-id=\"Evaluating-the-classifier-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Evaluating the classifier</a></div><div class=\"lev3 toc-item\"><a href=\"#Evaluation-on-the-CMU-data\" data-toc-modified-id=\"Evaluation-on-the-CMU-data-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Evaluation on the CMU data</a></div><div class=\"lev4 toc-item\"><a href=\"#ARCTIC-BDL-voice\" data-toc-modified-id=\"ARCTIC-BDL-voice-1211\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>ARCTIC BDL voice</a></div><div class=\"lev4 toc-item\"><a href=\"#ARCTIC-SLT-voice\" data-toc-modified-id=\"ARCTIC-SLT-voice-1212\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>ARCTIC SLT voice</a></div><div class=\"lev4 toc-item\"><a href=\"#CSTR-US-KED-Timit\" data-toc-modified-id=\"CSTR-US-KED-Timit-1213\"><span class=\"toc-item-num\">1.2.1.3&nbsp;&nbsp;</span>CSTR US KED Timit</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classification-based glottal closure instant detection\n",
    "\n",
    "This is an example of a Python code to train and test a classifier used to detect glottal closure instants (GCIs). See the [corresponding paper](paper/matousek_is2017_submit.pdf) for more details.\n",
    "\n",
    "[Scikit-learn toolkit](http://scikit-learn.org/stable/) is used to train and evaluate the classifier.\n",
    "\n",
    "Prerequisities:\n",
    "- [Python](https://www.python.org/) (version 2.7.13 used in this example)\n",
    "- [Numpy](http://www.numpy.org/) (1.12.1)\n",
    "- [Scipy](https://www.scipy.org/) (0.19.0)\n",
    "- [Scikit-learn](http://scikit-learn.org/stable/) (0.18.1)\n",
    "- [Pandas](http://pandas.pydata.org/) (0.19.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training the classifier\n",
    "\n",
    "For classification in this example, we use an [extremely randomized trees](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html) classifier (ERT) which was found to achieve the best performance in our experiments.\n",
    "\n",
    "Firstly, we define a classification pipeline that consists of a [feature scaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) and the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Init classification pipeline with standard scaler and\n",
    "# Extremely randomized tress classifier (with default parameters)\n",
    "pipe = Pipeline([('fscale', StandardScaler()),\n",
    "                ('classif', ExtraTreesClassifier(criterion='entropy', random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then, training data and its targets stored in a Numpy format is loaded. Peak-based features that describe properties of the current (to-be-classified) peak in a speech waveform and of the 6 neighboring peaks (3 prior and 3 susequent), resulting in a total number of 32 features for each peak candidate, were used (see the [corresponding paper](paper/matousek_is2017_submit.pdf)). Hand-crafted GCIs were used as targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# examples: 66256\n",
      "# features: 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Read training data and targets\n",
    "X = np.load('data/uwb/X_train_p3.npy')\n",
    "y = np.load('data/uwb/y_train.npy')\n",
    "print('# examples: {}'.format(X.shape[0]))\n",
    "print('# features: {}'.format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before the training, a grid of relevant parameters is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# Parameter grid for classification\n",
    "grid = {'classif__n_estimators': st.randint(100, 251),\n",
    "        'classif__max_features': st.uniform(0.5, 0.5),\n",
    "        'classif__min_samples_split': st.randint(2, 6),\n",
    "        'classif__min_samples_leaf': st.randint(1, 4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A [randomized grid search with cross-validation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) is then defined to search for the best classifier (hyper)parameters using a 3-fold cross-validation scheme ($cv=3$). The number of parameter settings that are sampled is set to $n\\_iter=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Define the grid search and cross-validation\n",
    "gs = RandomizedSearchCV(pipe, grid, n_iter=10, scoring='f1', cv=3, random_state=42, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that the parameters of the randomized grid search were set here to enable a faster training. In the [corresponding paper](paper/matousek_is2017_submit.pdf), $n\\_iter$ was set to 20 and $cv$ was set to 10. Of course, an [exhaustive search](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) can be also employed instead.\n",
    "\n",
    "The grid search object is then trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "# estimators     : 229\n",
      "max features     : 98.50%\n",
      "min samples split: 3\n",
      "min samples leaf : 2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Train the grid \n",
    "gs.fit(X, y)\n",
    "print('Best parameters found:')\n",
    "print('# estimators     : {}'.format(gs.best_estimator_.named_steps['classif'].get_params()['n_estimators']))\n",
    "print('max features     : {:.2%}'.format(gs.best_estimator_.named_steps['classif'].get_params()['max_features']))\n",
    "print('min samples split: {}'.format(gs.best_estimator_.named_steps['classif'].get_params()['min_samples_split']))\n",
    "print('min samples leaf : {}'.format(gs.best_estimator_.named_steps['classif'].get_params()['min_samples_leaf']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Summary of results for each parameter setting and each cross-validation fold could be stored to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, ExcelWriter\n",
    "# Import cross-validation results\n",
    "df = DataFrame(gs.cv_results_)\n",
    "df.to_csv('csv_results.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "or to an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "writer = ExcelWriter('cv_results.xlsx')\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluating the classifier\n",
    "\n",
    "The trained classifier is evaluated on the UWB test dataset using the [Scikit-learn](http://scikit-learn.org/stable/) toolkit again.\n",
    "\n",
    "The evaluation data and its targets stored in the same format as the training data is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# examples: 18026\n",
      "# features: 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Read testing data and targets\n",
    "X_test = np.load('data/uwb/X_test_p3.npy')\n",
    "y_test = np.load('data/uwb/y_test.npy')\n",
    "print('# examples: {}'.format(X_test.shape[0]))\n",
    "print('# features: {}'.format(X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The prediction of the classifier on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The comparison of the predictive and reference labels can be done in terms of _recall_, _precision_, and _F1-score_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (R)   : 96.46%\n",
      "Precision (P): 98.09%\n",
      "F1-score (F1): 97.27%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print('Recall (R)   : {:.2%}'.format(recall_score(y_test, y_pred)))\n",
    "print('Precision (P): {:.2%}'.format(precision_score(y_test, y_pred)))\n",
    "print('F1-score (F1): {:.2%}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that the results may slightly differ from those presented in the [paper](paper/matousek_is2017_submit.pdf) due to the random element present in the setting of both the extremely randomized trees classifier and the randomized grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the CMU data\n",
    "\n",
    "This time, the trained classifier is evaluated on the [CMU](http://festvox.org/dbs/index.html) test datasets. Since hand-crafted GCIs are not available for these datasets, we used the [Multi-Phase Algorithm](http://www.sciencedirect.com/science/article/pii/S0167639311000094) (MPA) to detect GCIs from the contemporaneous electroglottograph (EGG) signal and used the detected GCIs as the reference ones.\n",
    "\n",
    "Only the first 100 utterances of each voice were used in this example.\n",
    "\n",
    "Note that the results shown below concern the \"classification-way\" of evaluating the performance of a classifier and they were not presented in the [paper](paper/matousek_is2017_submit.pdf). Instead, a \"standard\" comparison of the detected and reference GCIs in terms of other common measures was conducted. Please see the [paper](paper/matousek_is2017_submit.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARCTIC BDL voice\n",
    "\n",
    "The prediction of the classifier on the CMU ARCTIC [BDL](http://festvox.org/cmu_arctic/dbs_bdl.html) test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# testing examples: 34485\n",
      "# features        : 32\n",
      "\n",
      "Recall (R)   : 97.61%\n",
      "Precision (P): 94.69%\n",
      "F1-score (F1): 96.13%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Read testing data and targets\n",
    "X_test = np.load('data/cmu/bdl/X_test_p3.npy')\n",
    "y_test = np.load('data/cmu/bdl/y_test.npy')\n",
    "print('# testing examples: {}'.format(X_test.shape[0]))\n",
    "print('# features        : {}'.format(X_test.shape[1]))\n",
    "\n",
    "# The prediction of the classifier on the CMU BDL test data\n",
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "# The comparison of the predictive and reference labes can be done in terms of recall, precision, and F1-score.\n",
    "print('')\n",
    "print('Recall (R)   : {:.2%}'.format(recall_score(y_test, y_pred)))\n",
    "print('Precision (P): {:.2%}'.format(precision_score(y_test, y_pred)))\n",
    "print('F1-score (F1): {:.2%}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### ARCTIC SLT voice\n",
    "\n",
    "The prediction of the classifier on the CMU ARCTIC [SLT](http://festvox.org/cmu_arctic/dbs_slt.html) test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# testing examples: 42156\n",
      "# features        : 32\n",
      "\n",
      "Recall (R)   : 99.69%\n",
      "Precision (P): 95.07%\n",
      "F1-score (F1): 97.33%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Read testing data and targets\n",
    "X_test = np.load('data/cmu/slt/X_test_p3.npy')\n",
    "y_test = np.load('data/cmu/slt/y_test.npy')\n",
    "print('# testing examples: {}'.format(X_test.shape[0]))\n",
    "print('# features        : {}'.format(X_test.shape[1]))\n",
    "\n",
    "# The prediction of the classifier on the CMU SLT test data\n",
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "# The comparison of the predictive and reference labes can be done in terms of recall, precision, and F1-score.\n",
    "print('')\n",
    "print('Recall (R)   : {:.2%}'.format(recall_score(y_test, y_pred)))\n",
    "print('Precision (P): {:.2%}'.format(precision_score(y_test, y_pred)))\n",
    "print('F1-score (F1): {:.2%}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### CSTR US KED Timit\n",
    "\n",
    "The prediction of the classifier on the CSTR US [KED](http://festvox.org/dbs/dbs_kdt.html) Timit test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# testing examples: 29177\n",
      "# features        : 32\n",
      "\n",
      "Recall (R)   : 96.96%\n",
      "Precision (P): 92.73%\n",
      "F1-score (F1): 94.79%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Read testing data and targets\n",
    "X_test = np.load('data/cmu/ked/X_test_p3.npy')\n",
    "y_test = np.load('data/cmu/ked/y_test.npy')\n",
    "print('# testing examples: {}'.format(X_test.shape[0]))\n",
    "print('# features        : {}'.format(X_test.shape[1]))\n",
    "\n",
    "# The prediction of the classifier on the CMU SLT test data\n",
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "# The comparison of the predictive and reference labes can be done in terms of recall, precision, and F1-score.\n",
    "print('')\n",
    "print('Recall (R)   : {:.2%}'.format(recall_score(y_test, y_pred)))\n",
    "print('Precision (P): {:.2%}'.format(precision_score(y_test, y_pred)))\n",
    "print('F1-score (F1): {:.2%}'.format(f1_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
